[
  {
    "definition": "When a user makes a purchasing decision, they will often try to weigh up the price against the features and their personal needs. When comparing products, they may try to do this for each one before making a decision. If this evaluation activity becomes too difficult, users may give up and make a rash decision. The comparison prevention deceptive pattern abuses this behaviour by making the comparison as difficult as possible. When a user struggles, they are more susceptible to cognitive biases such as social proof, the authority bias or the default effect. This enables the provider to steer them towards a decision that generates more revenue, but may not be in the user's best interest.",
    "example": "In this example T-Mobile makes it difficult for users to compare prices and plans. Features are bundled in slightly different ways in each of the plans, requiring users to do some complex evaluation and mental arithmetic to weigh up the differences. Taxes and fees are included in two of the plan prices, but not included in the third. Since the taxes and fees are not shown for the third plan the user cannot deduce if it is better value or not. Numerous details about the plans are not shown on this page, requiring the user to click multiple times to \"view full plan details\" for each plan. Hidden at the bottom of this page is a link that says \"Lowest priced plan\". Unlike the other plans, no price or information is shown. The user must click on it. This brings up a lightbox modal in a different style, requiring the user to memorise the price and key features before returning to the previous page. Overall, the user may not bother with all the effort needed to identify and understand the two cheaper plans, and they may end up choosing one of the two more expensive plans, delivering extra revenue to the business even though it may not be in their best interest.",
    "title": "comparison_prevention"
  },
  {
    "definition": "Confirmshaming works by triggering uncomfortable emotions, such as guilt or shame, to influence users' decision-making. Websites or apps employing this deceptive pattern often present users with opt-out button labels that are worded in a derogatory or belittling manner, making users feel bad about choosing not to engage with the offered service or feature. By targeting users' emotions and self-image, confirmshaming aims to increase the likelihood that users will give in to the desired action, ultimately benefiting the service provider.",
    "example": "eCommerce website mimedic.com sells first aid packs and medical supplies. IN 2018, Mymedic used the confirmshaming deceptive pattern. In asking permission for its website to send you notifications, the opt out link label was presented as “No, I don’t want to stay alive” or \"No, I prefer to bleed to death\". This is particularly troubling given that its target customers are people likely to be exposed to the trauma of accidents and death in their work (Source: Per Axbom, 2021).",
    "title": "confirmshaming"
  },
  {
    "definition": "The disguised ads deceptive pattern works by deliberately blurring the line between actual content and advertising, creating confusion for users. These ads are often designed to look like interface elements, related articles, or other content that users might be interested in, making it more likely that users will click on them. By doing this, website owners may generate more revenue from ad impressions, and advertisers may benefit from increased clickthrough rates that may result in more sales.",
    "example": "Softpedia, a popular software download website, often uses disguised ads on their software download pages to boost ad revenue. Their approach involves displaying advertisements with a prominent download button that closely resembles the actual download button for the desired software. This leads users to mistakenly click on the ad, thinking they are downloading the software.",
    "title": "Disguised_ads"
  },
  {
    "definition": "Fake scarcity works by creating an artificial sense of limited availability around a product or service, pushing users to act quickly out of fear of missing out. This is achieved by displaying misleading messages about low stock levels or high demand. By tapping into the scarcity cognitive bias, this deceptive pattern preys on users' natural tendency to assign more value to items that appear rare or exclusive, pushing them into making hasty purchasing decisions without fully evaluating their options.",
    "example": "The Shopify app “Sales & Stock Counter” is made by a company called HeyMerch. It makes it easy for store owners to show fake low stock messages, as shown in the first image (see red outlined area). In the promotional materials, they provide a guide outlining how to do this (see second image). The store owner can select options that cause it to display fake low stock counters and fake sales numbers.",
    "title": "Fake_scarcity"
  },
  {
    "definition": "The fake social proof deceptive pattern creates an illusion of popularity and credibility by presenting users with falsified or exaggerated endorsements, such as reviews, testimonials, or activity messages. This manipulation preys on the social proof cognitive bias, in which which individuals are likely to conform to the behaviour of others. It is a shortcut that allows people to avoid the hard work of carrying out a critical evaluation of their own. By using the fake social proof deceptive pattern, providers can trick users into making a purchase or engaging with their offerings.",
    "example": "Beeketing is a marketing automation company that makes software plugins for eCommerce stores. One of their products is called \"Sales Pop\". It causes an activity message overlay to appear on screen containing claims like “9 customers have bought item x together with item y” or “Alycia in San Francisco just bought item x 4 minutes ago”, as you can see in the first image below. In the Sales Pop documentation, they provide a guide outlining how to use the product to create a convincing fake scarcity deceptive pattern. As you can see in the second image, the store owner can pick a radio button telling the product to generate random locations, and a random \"time ago\".",
    "title": "Fake_social_proof"
  },
  {
    "definition": "When a user is placed under time pressure, they are less able to critically evaluate the information shown to them because they have less time and may experience anxiety or stress. Providers can use this to their advantage, to push them into completing an action that may not entirely be in the user's interest.",
    "example": "The Shopify app “Hurrify” is made by a company called Twozillas. It can be used to create various fake urgency messages, one of which is a fake countdown timer. In the first image, you can see what a user typically sees on a site that uses the Hurrify countdown timer. It's very prominent, animated and claims that the sale will end once the timer hits zero. However, the admin interface for sellers (second image) has a default configuration to \"Run the campaign allover again\" which means that the counter simply resets when it reaches zero. Update April 2023: Hurrify appears to have been banned from the Shopify app store.",
    "title": "Fake_urgency"
  },
  {
    "definition": "Forced action involves a provider offering users something they want - but requiring them to do something in return. It may be combined with other deceptive patterns like sneaking (so users don't notice it happening) or trick wording (to make the action seem more desirable than it is). Sometimes an optional action is presented as a forced action, through the use of visual interference or trick wording. In cookie consent interfaces, forced action is sometimes carried out through \"bundled consent\". This involves combining multiple agreements into a single action, and making it hard or impossible for a user to selectively grant consent.",
    "example": "In 2015, LinkedIn used forced action as part of their website registration process. In one of the steps, users were shown a harmless looking page titled \"Get stated by adding your email address\". Below this was a text field for their email address, and a prominent \"Continue\" button. This appeared to be mandatory, and users most likely felt it was harmless as almost all websites require an email address during registration. However, the true function of this was to access the user's email inbox and extract all of the email addresses it could find. Although the page did provide a description of this function, the text was grey on a blue background, making it relatively low contrast and hard to notice, and the textual content did not clearly state the consequences. Although the user could reject the request to continue, this was also unclear. The \"skip this step\" link was relatively small and hard to notice, positioned at the bottom right. Dan Schlosser provides further details in his article Linkedin Dark Patterns.",
    "title": "Forced_action"
  },
  {
    "definition": "Hard to cancel (aka \"Roach Motel\") is a deceptive pattern where it is easy to sign up for a service or subscription, but very difficult to cancel it. This typically involves hiding the cancellation option, requiring users to call customer services to cancel, and making the cancellation process overly complex and time-consuming. This can cause users to give up trying to cancel, and continue paying for the service for a longer period.",
    "example": "The New York Times made it easy to sign up for a subscription, but difficult to cancel, as users have reported being required to call customer service to cancel, waiting on hold for long periods, or being redirected to other web pages without being able to cancel their subscription. This leads to users paying for a service they no longer want or need. In one test it took roughly 8 minutes of conversation with a customer services rep to successfully cancel a subscription (source). Conversely, it takes a matter of seconds to create a new subscription.",
    "title": "Hard_to_cancel"
  },
  {
    "definition": "Hidden costs involve obscuring or omitting additional fees, charges, or costs until the user is well into the purchasing or sign-up process. By that point, the user has already invested time and effort into the transaction and is more likely to proceed despite the unexpected costs.",
    "example": "Ticket reseller Stubhub used hidden costs to drive revenue. Their method was to advertise a low price, draw users in through a lengthy series of steps, and then at the end immediately prior to payment, reveal a final higher price. At that point, the user had already spent time and energy, so they had to weigh up the time and energy cost of trying to find a cheaper price elsewhere (and risk of failing) versus just paying up. This is detailed in the research paper Price Salience and Product Choice (Blake et. al, 2021), who reported that users who were who weren’t shown the ticket fees upfront spent about 21% more money and were 14.1% more likely to complete a purchase.",
    "title": "Hidden_Costs"
  },
  {
    "definition": "The hidden subscription deceptive pattern typically works by employing some form of sneaking or misdirection. Users think they are buying one thing, when in fact there's a hidden legal stipulation that they are in fact signing up to a recurring subscription. Once they have signed up, the service is usually covert and the user is sent no emails or notifications reminding them that they are paying on a recurring basis, so that payments continue for as long as possible. It is also typically paired up with the hard to cancel deceptive pattern.",
    "example": "Adobe-owned UI design tool Figma sells itself on its collaborative capabilities, enabling teams of people to work together on designs. When a user creates a design in Figma, they can share it with anyone using the \"Share\" button (pictured top right in first image). Clicking the “Share” button causes a dialog box to appear (see second image), where they can choose a recipient and decide whether they “can edit” or “can view”. If the user picks the option “can edit”, this quietly creates a new monthly subscription for the recipient, which is automatically paid on the inviting user's credit card. This extra cost is not mentioned anywhere in the user interface. Since Figma already has the inviting user's credit card details on file, they can be charged without the user being notified in advance. Users frequently complain about this issue on social media (see third image).",
    "title": "Hidden_subscription"
  },
  {
    "definition": "Nagging is a form of adversarial resource depletion. Every time an app or a website interrupts the user with a request to do something, this depletes the user's time and attention. This is like a tax that the provider imposes on users who do not want to comply with the provider's wishes. Although the cost is non-financial, it adds up and eventually becomes non-trivial. At this point the user may decide that it’s more cost effective to just give in and agree to whatever the provider is asking for, even if it is against their best interests.",
    "example": "n 2018, Instagram aggressively nagged users to turn on notifications, repeating this regularly over a period of months. Users were not able to reject the request entirely – their only option to reject was \"Not Now\", which allowed the nagging to continue. (Reported by Gray et al., 2018. Image source: guidingtech.com)",
    "title": "Nagging"
  },
  {
    "definition": "Obstruction is a type of deceptive pattern that deliberately creates obstacles or roadblocks in the user's path, making it more difficult for them to complete a desired task or take a certain action. It is used to exhaust users and make them give up, when their goals are contrary to the business's revenue or growth objectives. It is also sometimes used to soften up users in preparation for a bigger deception. When users are frustrated or fatigued, they become more susceptible to manipulation.",
    "example": "Facebook used an obstruction technique by making it easy to agree to privacy-invading settings but difficult to reject them. Facebook's interface had a button to “accept and continue” with just one click, but to reject the settings, the user had to click an unclear button and toggle a switch to the left. This made it confusing for users, and they couldn't be sure if they successfully protected their privacy. (Image source: Norwegian Consumer Council, 2018)",
    "title": "Obstruction"
  },
  {
    "definition": "Preselection employs the default effect cognitive bias – a psychological phenomenon where people tend to go with the option that is already chosen for them, even if there are other choices available. Providers know this and often use it to take advantage of consumers. A common approach is to show a pre-ticked checkbox, though there are various other ways of doing this, including putting items in the user's shopping cart, or pre-selecting items in a series of steps. There are lots of reasons why this is a powerful deceptive pattern. Firstly, there’s simply the matter of awareness - users have to notice it, read it and work out what it all means. If the user doesn't, they'll scroll past completely unaware of the implications. There are other cognitive biases that may be employed in his deceptive pattern. For example, the content may be written to make the user feel that people to feel other people like them would accept the default so they should too (targeting the social proof bias). Alternatively, the content may use an authority figure to pressure users into accepting the default (targeting the authority bias).",
    "example": "In 2021, the Trump campaign famously used this deceptive pattern. A preselected checkbox for \"Make this a monthly recurring donation\" was included, tricking many donors into unintentional recurring payments. Then, later in the campaign they added a second preselected checkbox that tricked users into an additional donation. Numerous deceptive patterns were used in the Trump campaign, documented by Shane Goldmacher in the New York Times.",
    "title": "Preselection"
  },
  {
    "definition": "Sneaking involves intentionally withholding or obscuring information that is relevant to the user (e.g. additional costs or unwanted consequences), often in order to manipulate them into taking an action they would not otherwise choose.",
    "example": "In 2015, UK sports retailer sportsdirect.com was found to be sneaking an unwanted magazine subscription into users' shopping baskets during the checkout process. The magazine cost an extra £1, and was added without users' explicit consent or knowledge. If users noticed it, they had to actively remove it from their basket if they did not wish to purchase it.",
    "title": "Sneaking"
  },
  {
    "definition": "The trick wording deceptive pattern takes advantage of user expectations and ambiguous language to mislead and deceive users. It is normal for users to scan-read when they are online, as a way to cope with the sheer volume of information they are faced with. This means they don't read and dwell on every word on every page. Trick wording usually takes advantage of the scan reading strategy, by making a piece of content look like it is saying one thing, when in fact it is saying something else that is not in the user's best interests.",
    "example": "From 2010 to 2013, low-cost airline Ryanair used the trick wording deceptive pattern. During the flight booking process, Ryanair presented users with the instruction \"Please select a country of residence\" written prominently on a dropdown menu. If read on its own, users were likely to just select their country of residence from the dropdown and continue with their booking process. However, in doing so they would have inadvertently purchased travel insurance.For a user to choose not to purchase travel insurance, they were required to open the dropdown and scroll down to the label \"No travel insurance required\" which was nonsensically listed between two countries: Latvia and Lithuania. As you can see, Ryanair combined trick wording with the visual interference deceptive pattern to confuse and misdirect users.",
    "title": "Trick_wording"
  },
  {
    "definition": "There are numerous ways to interfere with the visual design of a page to hide, obscure or disguise information. Visual perception can be manipulated by using small, low contrast text. Comprehension can be manipulated by creating a chaotic or overwhelming interface. User's expectations can be violated by placing important information in styles or location they would not expect",
    "example": "In 2019, Tesla added an eCommerce feature to their mobile app, allowing Tesla car owners to buy upgrades for their vehicles, such as an autopilot that would unlock \"Full Self-Driving\" capabilities for $4,000. Some customers purchased this by mistake, and were outraged when they discovered that Tesla was refusing to provide a refund. Renowned author Nassim Nicholas Taleb complained on Twitter: _\"I unintentionally hit the buy button while the app was in my pocket\". _Hidden on the purchase screen was some small, low contrast text stating \"upgrades cannot be refunded\". This text was the lowest contrast text on the page, and was difficult to see (Image source: Reddit, 2019).",
    "title": "Visual_interference"
  }
]